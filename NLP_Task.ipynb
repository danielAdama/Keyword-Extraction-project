{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "#list to attach the respective data\n",
    "train_doc = []\n",
    "train_tags = []\n",
    "#directory to the text files in the train documents folder\n",
    "filenames_doc = glob('Train_docs/case*.txt')\n",
    "#directory to the text files in the train tags folder\n",
    "filenames_tag = glob('Train_tags/case*.txt')\n",
    "\n",
    "#iterate over each text file\n",
    "for file_doc in filenames_doc:\n",
    "    #open the current text file\n",
    "    with open((file_doc), 'r') as f:\n",
    "        #read that text file\n",
    "        read_doc = f.read()\n",
    "        #attach to the train_doc list\n",
    "        train_doc.append(read_doc)\n",
    "for file_tag in filenames_tag:\n",
    "    with open((file_tag), 'r') as n:\n",
    "        read_tag = n.read()\n",
    "        #attach to the train_tags list\n",
    "        train_tags.append(read_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "#keep data in a data frame\n",
    "train_doc = pd.DataFrame(train_doc[:])\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    #lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    #remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert back to list\n",
    "doc = train_doc[0].tolist()\n",
    "#create a vocabulary of words, ignore words that appear\n",
    "#in 85% of documents, and eliminate stopwords\n",
    "count_vect = CountVectorizer(max_df=0.85,stop_words=STOP_WORDS, preprocessor=preprocess)\n",
    "word_count_vect = count_vect.fit_transform(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 11141)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we have 80 rows and a vocabulary size of 12737\n",
    "word_count_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kurian',\n",
       " 'joseph',\n",
       " 'leave',\n",
       " 'granted',\n",
       " 'special',\n",
       " 'petition',\n",
       " 'civil',\n",
       " 'around',\n",
       " 'acres',\n",
       " 'land']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check 10 words from our vocabulary\n",
    "list(count_vect.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfTransformer to Compute Inverse Document Frequency(IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.29583687, 4.70130197, 4.70130197, ..., 4.70130197, 4.70130197,\n",
       "       4.29583687])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True, norm='max',sublinear_tf=False)\n",
    "tfidf_transformer.fit(word_count_vect)\n",
    "#here are some Inverse document frequencies(IDF)s\n",
    "tfidf_transformer.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our IDF computed, we are now ready to compute TF-IDF and extract the top tags from the test document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the test data as we did earlier\n",
    "test_doc = []\n",
    "#directory to the text files in the train documents folder\n",
    "filenames_doc = glob('Test_docs/case*.txt')\n",
    "\n",
    "#iterate over each text file\n",
    "for file_doc in filenames_doc:\n",
    "    #open the current text file\n",
    "    with open((file_doc), 'r') as f:\n",
    "        #read that text file\n",
    "        read_doc = f.read()\n",
    "        #attach to the train_doc list\n",
    "        test_doc.append(read_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    #join both the coo_matrix.col and data together\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1],x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "    \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    for idx, score in sorted_items:\n",
    "        feature_name = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature names and its corresponding score \n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "        \n",
    "    #create a tuples of feature,score\n",
    "    results = {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you only need to do this once\n",
    "feature_names=count_vect.get_feature_names()\n",
    "\n",
    "def get_tags(idx):\n",
    "    \n",
    "    # get the document that we want to extract tags from\n",
    "    #doc=test_doc[0]\n",
    "    \n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(count_vect.transform([test_doc[idx]]))\n",
    "    \n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "    \n",
    "    #extract only the top n; n here is 10\n",
    "    tags=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    return tags\n",
    "\n",
    "# now print the results\n",
    "def print_result(idx,tags):\n",
    "    print('===='*10+'Body'+'===='*10)\n",
    "    print(test_doc[idx])\n",
    "    print('===='*10+'tags'+'===='*10)\n",
    "    for t in tags:\n",
    "        print(t,tags[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tags from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================Body========================================\n",
      "\n",
      "\n",
      "1. The Petitioner is being tried before the Sessions Judge, Jodhpur for offences punishable Under Sections 370(4), 342, 354A, 376(2)(f), 376D, 506, 509/34, 120B, Indian Penal Code, Sections 23 and 26, Juvenile Justice (Care and Protection of Children) Act, 2000 and Sections 5(F)/6, 5(G)/6, 7/8, Protection of Children From Sexual Offences Act, 2012. As earlier application for bail filed by him having been declined, a second application was moved before the Trial Court which too came to be rejected by the said Court. The matter was then taken up before the High Court who has concurred with the view taken by the Trial Court and dismissed the plea for bail. The present special leave petition calls in question the correctness of the said order.\n",
      "\n",
      "2. When this petition initially came up before us on 15.10.2014 Mr. Salman Khurshid, learned senior counsel appearing for the Appellant submitted that although several witnesses for the prosecution had already been examined at the trial, the Petitioner shall be satisfied if he is permitted to refresh his application for enlargement on bail after the examination of the material witnesses. The prosecution has it is common ground named six material witnesses in terms of a list filed before this Court, two out of whom have already been examined and cross-examined while the third is still under cross-examination, although the Petitioner's counsel has concluded the cross examination on his part. This implies that there are still three other witnesses apart from the one who is under cross-examination that need to be examined at the trial. Mr. Khurshid's submission that the Petitioner will be satisfied if he is allowed to refresh his application for enlargement on bail after examination of the material witnesses clearly implied that the application for bail on merit was as good as withdrawn till such time the material witnesses were examined before the Trial Court. What had all the same been argued by Mr. Khurshid was that the medical condition of the Petitioner called for immediate surgery for which purpose he had placed reliance upon a certificate issued by Dr. Maheep Singh Gaur. It was argued that the Petitioner would like to be evaluated at Kumud Chawla Gamma Knife Centre, Goodwill Hospital and Research Centre, NOIDA. We had in view of this submission made at the Bar directed constitution of a Medical Board by the Director of AI-IMS to review the medical papers relevant to the Petitioner's present condition and to submit a report as to whether there was any need for surgery as suggested by the Petitioner's doctor. We had left it open to the Medical Board to call the Petitioner for a clinical examination should if it considered necessary to do so.\n",
      "\n",
      "3. A Board comprising as many as 8 Doctors from different specialities was accordingly constituted by the AIIMS before whom the Petitioner was produced in person for a clinical examination, apart from evaluation of his medical papers. The Board has based on their clinical examination and investigations submitted a report dated 02.01.2015 in which it has opined:\n",
      "\n",
      "\"On basis of above examination and investigations by the Medical Board, he was diagnosed to be suffering from Trigeminal Neuralgia with degenerative disc disease of the lumbar spine with Hypothyroidism and Benign Hyperplasia of Prostate. Radiological and blood investigation reports are enclosed in original.\n",
      "\n",
      "At present, none of the above mentioned disease require surgical management but requires appropriate routine medical management on OPD basis.\n",
      "\n",
      "The medical board concluded at 6.00 p.m.\"\n",
      "\n",
      "4. It is evident from that above that the Petitioner does not require any surgical intervention at this stage and that the diseases which he is found to be suffering from like Trigeminal Neuralgia, degenerative disc disease of the lumbar spine, Hypothyroidism and Benign Hyperplasia of Prostate can be handled in the OPD. We have no reason to doubt or reject the opinion given by the experts from the premier medical institute of the country. Mr. Vikas Singh, learned senior counsel all the same argued that some of the diseases namely degenerative disc disease of the lumbar spine with Hypothyroidism and Benign Hyperplasia of Prostate was developed by the Petitioner during incarnation. There is nothing before us to support even that submission of Learned Counsel. Be that as it may since the Board has suggested only medical management on OPD basis, there is no compelling reason for us to enlarge the Petitioner on bail at this stage when the Petitioner is facing serious charges some of which are punishable by imprisonment for life.\n",
      "\n",
      "5. Mr. Vikas Singh at this stage submitted that the Petitioner has been earlier treated by Dr. Arun Kumar Tyagi, Arogayadham Hospital and would like to continue with the treatment advised by him. There is no serious objection to that prayer being allowed. We also see no reason why the Doctor named by Learned Counsel for the Petitioner should not be allowed to visit the Petitioner in jail to administer such treatment as is considered necessary of course at the risk of the Petitioner.\n",
      "\n",
      "6. It was next contended by Mr. Vikas Singh that the three witnesses described as material witnesses by the prosecution have not appeared despite efforts made by the Trial Court. He submits that in any case those witnesses are not material for purpose of determining whether the incident in question had indeed taken place. On behalf of the Respondent it was submitted that the Respondents had named only six out of a total of 58 witnesses as material witnesses, three of whom are already examined as mentioned earlier while the remaining three will be produced no sooner the third witness correctly made cross-examination is discharged. In that view all that we need to say is that the trial court shall take such steps as are necessary to ensure that the trial of the Petitioner does not get delayed unduly because of nonavailability of witnesses. The trial will we are confident take all such steps as are necessary to have the witnesses served and produced before the Trial Court on such dates as may be fixed by it. With these observations this special leave petition fails and is hereby dismissed. Needless to say that after the recording of the material witnesses is complete, the Petitioner shall be free to move a fresh application for grant of bail to him. In case any such application is made the trial court shall consider the same on its merits. We express no opinion on the merits of any such application.\n",
      "\n",
      "SLP (C) Nos. 4916 of 2014 and 4918-4919 of 2014:\n",
      "\n",
      "Post in May, 2015.\n",
      "\n",
      "\n",
      "========================================tags========================================\n",
      "petitioner 1.0\n",
      "witnesses 0.982\n",
      "bail 0.751\n",
      "medical 0.702\n",
      "examination 0.605\n",
      "trial 0.597\n",
      "disease 0.503\n",
      "board 0.48\n",
      "material 0.413\n",
      "benign 0.377\n"
     ]
    }
   ],
   "source": [
    "#enter the document number, idx max is 100\n",
    "idx = 16\n",
    "tags = get_tags(idx)\n",
    "print_result(idx,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tags from the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Document</th>\n",
       "      <th>Test Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nP. Venkatarama Reddi, J.\\n\\n1. The opinion...</td>\n",
       "      <td>{'assessee': 1.0, 'tax': 0.745, 'income': 0.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nG.B. Pattanaik, J.\\n\\n1. This batch of Spe...</td>\n",
       "      <td>{'shops': 1.0, 'excise': 0.924, 'liquor': 0.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n1. After hearing the Learned Counsel for b...</td>\n",
       "      <td>{'excise': 1.0, 'notification': 0.519, 'cestat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n1. This appeal is directed against the jud...</td>\n",
       "      <td>{'pw': 1.0, 'appellant': 0.807, 'trial': 0.697...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n1. An issue raised by the appellants was t...</td>\n",
       "      <td>{'search': 1.0, 'shop': 0.73, 'count': 0.311, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\\n\\nVikramajit Sen, J.\\n\\n1. This Appeal assai...</td>\n",
       "      <td>{'shares': 1.0, 'buy': 0.473, 'target': 0.37, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\\n\\nAnil R. Dave, J.\\n\\n1. Leave granted.\\n\\n2...</td>\n",
       "      <td>{'lakhs': 1.0, 'sum': 0.985, 'deposited': 0.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\\n\\nAnil R. Dave, J.\\n\\n1 This appeal has been...</td>\n",
       "      <td>{'document': 1.0, 'property': 0.85, 'late': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\\n\\n1. By this interlocutory application, Mr. ...</td>\n",
       "      <td>{'kerala': 1.0, 'mr': 0.674, 'dogs': 0.591, 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>\\n\\n1. Having heard Learned Counsel appearing ...</td>\n",
       "      <td>{'missing': 1.0, 'child': 0.878, 'director': 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Test Document  \\\n",
       "0    \\n\\nP. Venkatarama Reddi, J.\\n\\n1. The opinion...   \n",
       "1    \\n\\nG.B. Pattanaik, J.\\n\\n1. This batch of Spe...   \n",
       "2    \\n\\n1. After hearing the Learned Counsel for b...   \n",
       "3    \\n\\n1. This appeal is directed against the jud...   \n",
       "4    \\n\\n1. An issue raised by the appellants was t...   \n",
       "..                                                 ...   \n",
       "96   \\n\\nVikramajit Sen, J.\\n\\n1. This Appeal assai...   \n",
       "97   \\n\\nAnil R. Dave, J.\\n\\n1. Leave granted.\\n\\n2...   \n",
       "98   \\n\\nAnil R. Dave, J.\\n\\n1 This appeal has been...   \n",
       "99   \\n\\n1. By this interlocutory application, Mr. ...   \n",
       "100  \\n\\n1. Having heard Learned Counsel appearing ...   \n",
       "\n",
       "                                             Test Tags  \n",
       "0    {'assessee': 1.0, 'tax': 0.745, 'income': 0.50...  \n",
       "1    {'shops': 1.0, 'excise': 0.924, 'liquor': 0.70...  \n",
       "2    {'excise': 1.0, 'notification': 0.519, 'cestat...  \n",
       "3    {'pw': 1.0, 'appellant': 0.807, 'trial': 0.697...  \n",
       "4    {'search': 1.0, 'shop': 0.73, 'count': 0.311, ...  \n",
       "..                                                 ...  \n",
       "96   {'shares': 1.0, 'buy': 0.473, 'target': 0.37, ...  \n",
       "97   {'lakhs': 1.0, 'sum': 0.985, 'deposited': 0.93...  \n",
       "98   {'document': 1.0, 'property': 0.85, 'late': 0....  \n",
       "99   {'kerala': 1.0, 'mr': 0.674, 'dogs': 0.591, 's...  \n",
       "100  {'missing': 1.0, 'child': 0.878, 'director': 0...  \n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate tf-idf for all documents in your list \n",
    "tf_idf_vector = tfidf_transformer.transform(count_vect.transform(test_doc))\n",
    "\n",
    "results = []\n",
    "for i in range(tf_idf_vector.shape[0]):\n",
    "    \n",
    "    #get vector for each document\n",
    "    curr_vector=tf_idf_vector[i]\n",
    "    \n",
    "    #sort the tf-idf vector by descending order of scores\n",
    "    sorted_items=sort_coo(curr_vector.tocoo())\n",
    "\n",
    "    #extract only the top n, n=10\n",
    "    tags=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    results.append(tags)\n",
    "\n",
    "Test_doc_tags=pd.DataFrame(zip(test_doc,results),columns=['Test Document','Test Tags'])\n",
    "#save document as csv\n",
    "Test_doc_tags.to_csv('Test tags.csv')\n",
    "Test_doc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
